{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Everybody\n",
    "## C3: Using Python to Access Web Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Week 1: Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Python and a programming text editor and write a program that prints one line other than 'hello world', then take two screen shots and upload them below. You should use the command line to execute the Python program you wrote in the text editor. Please do *not* use the IDLE Python Shell, the Python Interpreter (>>>), or a shortcut in your text editor to run the code.\n",
    "\n",
    "Refer to script: **c3_w1_assignment.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Week 2: Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding Numbers in a Haystack**\n",
    "\n",
    "In this assignment you will read through and parse a file with text and numbers. You will extract all the numbers in the file and compute the sum of the numbers.\n",
    "\n",
    "**Data Files**\n",
    "We provide two files for this assignment. One is a sample file where we give you the sum for your testing and the other is the actual data you need to process for the assignment.\n",
    "\n",
    "* Sample data: http://py4e-data.dr-chuck.net/regex_sum_42.txt (There are 90 values with a sum=445833)\n",
    "* Actual data: http://py4e-data.dr-chuck.net/regex_sum_1552408.txt (There are 80 values and the sum ends with 472)\n",
    "\n",
    "These links open in a new window. Make sure to save the file into the same folder as you will be writing your Python program. **Note:** Each student will have a distinct data file for the assignment - so only use your own data file for analysis.\n",
    "\n",
    "**Data Format**\n",
    "The file contains much of the text from the introduction of the textbook except that random numbers are inserted throughout the text. Here is a sample of the output you might see:\n",
    "```\n",
    "Why should you learn to write programs? 7746\n",
    "12 1929 8827\n",
    "Writing programs (or programming) is a very creative \n",
    "7 and rewarding activity.  You can write programs for \n",
    "many reasons, ranging from making your living to solving\n",
    "8837 a difficult data analysis problem to having fun to helping 128\n",
    "someone else solve a problem.  This book assumes that \n",
    "everyone needs to know how to program ...\n",
    "```\n",
    "The sum for the sample text above is **27486**. The numbers can appear anywhere in the line. There can be any number of numbers in each line (including none).\n",
    "\n",
    "**Handling The Data**\n",
    "The basic outline of this problem is to read the file, look for integers using the **re.findall()**, looking for a regular expression of **'[0-9]+'** and then converting the extracted strings to integers and summing up the integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of numbers is: 378472\n"
     ]
    }
   ],
   "source": [
    "# import regular expression library\n",
    "import re\n",
    "\n",
    "# read file\n",
    "# handle = open('regex_sum_42.txt') # sample data\n",
    "handle = open('regex_sum_1552408.txt') # actual data\n",
    "\n",
    "# create an empty numbers list\n",
    "numbers = list()\n",
    "\n",
    "# loop through file, strip out new lines and use regex to find numbers\n",
    "for line in handle:\n",
    "    line = line.strip()\n",
    "    num = re.findall('([0-9]+)', line)\n",
    "    # print(num)\n",
    "\n",
    "    # second loop to append numbers to the numbers list\n",
    "    for number in num:\n",
    "        numbers.append(int(number))\n",
    "\n",
    "# print sum of numbers\n",
    "print('Sum of numbers is:', sum(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Week 3: Networks and Sockets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploring the HyperText Transport Protocol**\n",
    "\n",
    "You are to retrieve the following document using the HTTP protocol in a way that you can examine the HTTP Response headers.\n",
    "\n",
    "http://data.pr4e.org/intro-short.txt\n",
    "\n",
    "There are three ways that you might retrieve this web page and look at the response headers:\n",
    "\n",
    "* Preferred: Modify the socket1.py program to retrieve the above URL and print out the headers and data. Make sure to change the code to retrieve the above URL - the values are different for each URL.\n",
    "* Open the URL in a web browser with a developer console or FireBug and manually examine the headers that are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\n",
      "Date: Wed, 01 Jun 2022 00:48:35 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\n",
      "ETag: \"1d3-54f6609240717\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 467\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: text/plain\n",
      "\n",
      "Why should you learn to write programs?\n",
      "\n",
      "Writing programs (or programming) is a very creative \n",
      "and rewarding activity.  You can write programs for \n",
      "many reasons, ranging from making your living to solving\n",
      "a difficult data analysis problem to having fun to helping\n",
      "someone else solve a problem.  This book assumes that \n",
      "everyone needs to know how to program, and that once \n",
      "you know how to program you will figure out what you want \n",
      "to do with your newfound skills.  \n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/intro-short.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the header values in each of the fields below:.\n",
    "\n",
    "```\n",
    "Last-Modified:\n",
    "Sat, 13 May 2017 11:22:22 GMT\n",
    " \n",
    "ETag:\n",
    "1d3-54f6609240717\n",
    " \n",
    "Content-Length:\n",
    "467\n",
    " \n",
    "Cache-Control:\n",
    "max-age=0, no-cache, no-store, must-revalidate\n",
    " \n",
    "Content-Type:\n",
    "text/plain\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Week 4: Programs that Surf the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scraping Numbers from HTML using BeautifulSoup**\n",
    "\n",
    "In this assignment you will write a Python program similar to http://www.py4e.com/code3/urllink2.py. The program will use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file.\n",
    "\n",
    "We provide two files for this assignment. One is a sample file where we give you the sum for your testing and the other is the actual data you need to process for the assignment.\n",
    "* Sample data: http://py4e-data.dr-chuck.net/comments_42.html (Sum=2553)\n",
    "* Actual data: http://py4e-data.dr-chuck.net/comments_1552410.html (Sum ends with 31)\n",
    "\n",
    "You do not need to save these files to your folder since your program will read the data directly from the URL. \n",
    "\n",
    "**Note:** Each student will have a distinct data url for the assignment - so only use your own data url for analysis.\n",
    "\n",
    "**Data Format**\n",
    "The file is a table of names and comment counts. You can ignore most of the data in the file except for lines like the following:\n",
    "```\n",
    "<tr><td>Modu</td><td><span class=\"comments\">90</span></td></tr>\n",
    "<tr><td>Kenzie</td><td><span class=\"comments\">88</span></td></tr>\n",
    "<tr><td>Hubert</td><td><span class=\"comments\">87</span></td></tr>\n",
    "```\n",
    "\n",
    "You are to find all the <span> tags in the file and pull out the numbers from the tag and sum the numbers.\n",
    "\n",
    "Look at the sample code provided (https://www.py4e.com/code3/urllink2.py). It shows how to find all of a certain kind of tag, loop through the tags and extract the various aspects of the tags.\n",
    "```\n",
    "...\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "   # Look at the parts of a tag\n",
    "   print 'TAG:',tag\n",
    "   print 'URL:',tag.get('href', None)\n",
    "   print 'Contents:',tag.contents[0]\n",
    "   print 'Attrs:',tag.attrs\n",
    "```\n",
    "\n",
    "You need to adjust this code to look for **span** tags and pull out the text content of the span tag, convert them to integers and add them up to complete the assignment.\n",
    "\n",
    "**Sample Execution**\n",
    "```\n",
    "$ python3 solution.py\n",
    "Enter - http://py4e-data.dr-chuck.net/comments_42.html\n",
    "Count 50\n",
    "Sum 2...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2331\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# ignore ssl certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# prompt user to input URL\n",
    "url = input('Enter - ')\n",
    "\n",
    "# open url\n",
    "html = urlopen(url, context=ctx).read()\n",
    "\n",
    "# use beautifulsoup html parser\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# create an empty list snum\n",
    "snum = list()\n",
    "\n",
    "# Retrieve all of the span tags and append to snum list\n",
    "tags = soup('span')\n",
    "for tag in tags:\n",
    "    # append number from span tag to snum\n",
    "    snum.append(int(tag.string))\n",
    "\n",
    "# print out sum of numbers\n",
    "print(sum(snum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Following Links in Python**\n",
    "\n",
    "In this assignment you will write a Python program that expands on http://www.py4e.com/code3/urllinks.py. The program will use **urllib** to read the HTML from the data files below, extract the href= vaues from the anchor tags, scan for a tag that is in a particular position relative to the first name in the list, follow that link and repeat the process a number of times and report the last name you find.\n",
    "\n",
    "We provide two files for this assignment. One is a sample file where we give you the name for your testing and the other is the actual data you need to process for the assignment\n",
    "\n",
    "* Sample problem: Start at http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
    "Find the link at position **3** (the first name is 1). Follow that link. Repeat this process **4** times. The answer is the last name that you retrieve.\n",
    "Sequence of names: Fikret Montgomery Mhairade Butchi Anayah\n",
    "Last name in sequence: Anayah\n",
    "* Actual problem: Start at: http://py4e-data.dr-chuck.net/known_by_Limbiadhe.html\n",
    "Find the link at position **18** (the first name is 1). Follow that link. Repeat this process **7** times. The answer is the last name that you retrieve.\n",
    "\n",
    "**Hint:** The first character of the name of the last page that you will load is: P\n",
    "\n",
    "**Strategy**\n",
    "The web pages tweak the height between the links and hide the page after a few seconds to make it difficult for you to do the assignment without writing a Python program. But frankly with a little effort and patience you can overcome these attempts to make it a little harder to complete the assignment without writing a Python program. But that is not the point. The point is to write a clever Python program to solve the program.\n",
    "\n",
    "**Sample execution**\n",
    "\n",
    "Here is a sample execution of a solution:\n",
    "```\n",
    "$ python3 solution.py\n",
    "Enter URL: http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
    "Enter count: 4\n",
    "Enter position: 3\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Montgomery.html\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Mhairade.html\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Butchi.html\n",
    "Retrieving: http://py4e-data.dr-chuck.net/known_by_Anayah.html\n",
    "```\n",
    "\n",
    "The answer to the assignment for this execution is \"Anayah\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving: http://py4e-data.dr-chuck.net/known_by_Limbiadhe.html\n",
      "retrieving: http://py4e-data.dr-chuck.net/known_by_Haydon.html\n",
      "retrieving: http://py4e-data.dr-chuck.net/known_by_Elisha.html\n",
      "retrieving: http://py4e-data.dr-chuck.net/known_by_Rajan.html\n",
      "retrieving: http://py4e-data.dr-chuck.net/known_by_Aslam.html\n",
      "retrieving: http://py4e-data.dr-chuck.net/known_by_Kaylan.html\n",
      "retrieving: http://py4e-data.dr-chuck.net/known_by_Kiaran.html\n",
      "Sequence of names: ['Haydon', 'Elisha', 'Rajan', 'Aslam', 'Kaylan', 'Kiaran', 'Pascoe']\n",
      "Last name in sequence: Pascoe\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# ignore ssl certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# prompt user to input URL\n",
    "url = input('Enter URL:')\n",
    "\n",
    "# prompt user to input count\n",
    "count = input('Enter count:')\n",
    "try:\n",
    "    count = int(count)\n",
    "except:\n",
    "    print('Please enter a number as count')\n",
    "    quit()\n",
    "\n",
    "# prompt user to input position\n",
    "pos = input('Enter position:')\n",
    "try:\n",
    "    pos = int(pos)\n",
    "except:\n",
    "    print('Please enter a number as position')\n",
    "    quit()\n",
    "\n",
    "names = []\n",
    "\n",
    "while int(count) > 0:\n",
    "    # print which URL we are retrieving name from\n",
    "    print (\"retrieving: {0}\".format(url))\n",
    "\n",
    "    # open url\n",
    "    html = urlopen(url, context=ctx).read()\n",
    "\n",
    "    # use beautifulsoup html parser\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # pull anchors and append name to names list\n",
    "    anchors = soup('a')\n",
    "    name = anchors[pos-1].string\n",
    "    names.append(name)\n",
    "    # print(names)\n",
    "    url = anchors[pos-1]['href']\n",
    "    count = count - 1\n",
    "\n",
    "print('Sequence of names:', names)\n",
    "print('Last name in sequence:', names[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Week 5: Web Services and XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Data from XML**\n",
    "\n",
    "In this assignment you will write a Python program somewhat similar to http://www.py4e.com/code3/geoxml.py. The program will prompt for a URL, read the XML data from that URL using **urllib** and then parse and extract the comment counts from the XML data, compute the sum of the numbers in the file.\n",
    "\n",
    "We provide two files for this assignment. One is a sample file where we give you the sum for your testing and the other is the actual data you need to process for the assignment.\n",
    "\n",
    "* Sample data: http://py4e-data.dr-chuck.net/comments_42.xml (Sum=2553)\n",
    "* Actual data: http://py4e-data.dr-chuck.net/comments_1552412.xml (Sum ends with 97)\n",
    "\n",
    "You do not need to save these files to your folder since your program will read the data directly from the URL. Note: Each student will have a distinct data url for the assignment - so only use your own data url for analysis.\n",
    "\n",
    "**Data Format and Approach**\n",
    "The data consists of a number of names and comment counts in XML as follows:\n",
    "```\n",
    "<comment>\n",
    "  <name>Matthias</name>\n",
    "  <count>97</count>\n",
    "</comment>\n",
    "```\n",
    "\n",
    "You are to look through all the **<comment>** tags and find the **<count>** values sum the numbers. The closest sample code that shows how to parse XML is geoxml.py. But since the nesting of the elements in our data is different than the data we are parsing in that sample code you will have to make real changes to the code.\n",
    "\n",
    "To make the code a little simpler, you can use an XPath selector string to look through the entire tree of XML for any tag named 'count' with the following line of code:\n",
    "```\n",
    "counts = tree.findall('.//count')\n",
    "```\n",
    "Take a look at the Python ElementTree documentation and look for the supported XPath syntax for details. You could also work from the top of the XML down to the comments node and then loop through the child nodes of the comments node.\n",
    "\n",
    "**Sample Execution**\n",
    "```\n",
    "$ python3 solution.py\n",
    "Enter location: http://py4e-data.dr-chuck.net/comments_42.xml\n",
    "Retrieving http://py4e-data.dr-chuck.net/comments_42.xml\n",
    "Retrieved 4189 characters\n",
    "Count: 50\n",
    "Sum: 2...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving: http://py4e-data.dr-chuck.net/comments_1552412.xml\n",
      "Retrieved 4228 characters\n",
      "Count: 50\n",
      "Sum: 2497\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import ssl\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# ignore ssl certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# prompt user to enter URL\n",
    "url = input('Please enter URL:')\n",
    "print('Retrieving:', url)\n",
    "\n",
    "# make connection and get response\n",
    "fhand = urllib.request.urlopen(url)\n",
    "response = fhand.read()\n",
    "\n",
    "# print length of charatcers received\n",
    "print('Retrieved', len(response), 'characters')\n",
    "\n",
    "# convert response into xml tree\n",
    "tree = ET.fromstring(response)\n",
    "\n",
    "# find all count tage\n",
    "counts =  tree.findall('.//count')\n",
    "\n",
    "# print number of count tags found\n",
    "print('Count:', len(counts))\n",
    "\n",
    "# calculate and print sum of count values\n",
    "sum = 0\n",
    "\n",
    "for count in counts:\n",
    "    sum = sum + int(count.text)\n",
    "print ('Sum:', sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Week 6: JSON and the REST Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Data from JSON**\n",
    "\n",
    "In this assignment you will write a Python program somewhat similar to http://www.py4e.com/code3/json2.py. The program will prompt for a URL, read the JSON data from that URL using urllib and then parse and extract the comment counts from the JSON data, compute the sum of the numbers in the file and enter the sum below:\n",
    "\n",
    "We provide two files for this assignment. One is a sample file where we give you the sum for your testing and the other is the actual data you need to process for the assignment.\n",
    "\n",
    "* Sample data: http://py4e-data.dr-chuck.net/comments_42.json (Sum=2553)\n",
    "* Actual data: http://py4e-data.dr-chuck.net/comments_1552413.json (Sum ends with 31)\n",
    "\n",
    "You do not need to save these files to your folder since your program will read the data directly from the URL. **Note:** Each student will have a distinct data url for the assignment - so only use your own data url for analysis.\n",
    "\n",
    "**Data Format**\n",
    "The data consists of a number of names and comment counts in JSON as follows:\n",
    "```\n",
    "{\n",
    "  comments: [\n",
    "    {\n",
    "      name: \"Matthias\"\n",
    "      count: 97\n",
    "    },\n",
    "    {\n",
    "      name: \"Geomer\"\n",
    "      count: 97\n",
    "    }\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "The closest sample code that shows how to parse JSON and extract a list is https://www.py4e.com/code3/json2.py. You might also want to look at https://www.py4e.com/code3/geoxml.py to see how to prompt for a URL and retrieve data from a URL.\n",
    "\n",
    "**Sample Execution**\n",
    "```\n",
    "$ python3 solution.py\n",
    "Enter location: http://py4e-data.dr-chuck.net/comments_42.json\n",
    "Retrieving http://py4e-data.dr-chuck.net/comments_42.json\n",
    "Retrieved 2733 characters\n",
    "Count: 50\n",
    "Sum: 2...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving: http://py4e-data.dr-chuck.net/comments_1552413.json\n",
      "Retrieved 2741 characters\n",
      "Count: 50\n",
      "Sum: 2431\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import ssl\n",
    "import json\n",
    "\n",
    "# ignore ssl certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter location:')\n",
    "# test url\n",
    "# url = 'http://py4e-data.dr-chuck.net/comments_42.json'\n",
    "# actual url\n",
    "# url = 'http://py4e-data.dr-chuck.net/comments_1552413.json'\n",
    "\n",
    "print('Retrieving:', url)\n",
    "\n",
    "# make connection and get response\n",
    "fhand = urllib.request.urlopen(url)\n",
    "response = fhand.read().decode()\n",
    "\n",
    "# print \n",
    "print('Retrieved', len(response), 'characters')\n",
    "\n",
    "# load json\n",
    "data = json.loads(response)\n",
    "# print(data)\n",
    "\n",
    "# strip out comments part into a list\n",
    "comments = list()\n",
    "comments = data['comments']\n",
    "print('Count:', len(comments))\n",
    "\n",
    "# loop through and count the number of \"counts\" and sum it up\n",
    "sum = 0\n",
    "for item in comments:\n",
    "    # print(item)\n",
    "    sum = sum + int(item['count'])\n",
    "print('Sum:', sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling a JSON API**\n",
    "\n",
    "In this assignment you will write a Python program somewhat similar to http://www.py4e.com/code3/geojson.py. The program will prompt for a location, contact a web service and retrieve JSON for the web service and parse that data, and retrieve the first **place_id** from the JSON. A place ID is a textual identifier that uniquely identifies a place as within Google Maps.\n",
    "\n",
    "**API End Points**\n",
    "\n",
    "To complete this assignment, you should use this API endpoint that has a static subset of the Google Data: http://py4e-data.dr-chuck.net/json?\n",
    "\n",
    "This API uses the same parameter (address) as the Google API. This API also has no rate limit so you can test as often as you like. If you visit the URL with no parameters, you get \"No address...\" response.\n",
    "\n",
    "To call the API, you need to include a **key=** parameter and provide the address that you are requesting as the **address=** parameter that is properly URL encoded using the urllib.parse.urlencode() function as shown in http://www.py4e.com/code3/geojson.py\n",
    "\n",
    "Make sure to check that your code is using the API endpoint is as shown above. You will get different results from the **geojson** and **json** endpoints so make sure you are using the same end point as this autograder is using.\n",
    "\n",
    "**Test Data / Sample Execution**\n",
    "\n",
    "You can test to see if your program is working with a location of \"South Federal University\" which will have a **place_id** of \"ChIJNeHD4p-540AR2Q0_ZjwmKJ8\".\n",
    "```\n",
    "$ python3 solution.py\n",
    "Enter location: South Federal University\n",
    "Retrieving http://...\n",
    "Retrieved 2445 characters\n",
    "Place id ChIJNeHD4p-540AR2Q0_ZjwmKJ8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving http://py4e-data.dr-chuck.net/json?address=Purdue+University+Indianapolis&key=42\n",
      "Retrieved 1783 characters\n",
      "Place id ChIJA2p5p_9Qa4gRfOq5QPadjtY\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "import ssl\n",
    "\n",
    "api_key = False\n",
    "# If you have a Google Places API key, enter it here\n",
    "# api_key = 'AIzaSy___IDByT70'\n",
    "# https://developers.google.com/maps/documentation/geocoding/intro\n",
    "\n",
    "if api_key is False:\n",
    "    api_key = 42\n",
    "    serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
    "else :\n",
    "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "while True:\n",
    "    # prompt user to enter location\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    # create a parms dictionary and add the user enter location as value to address key\n",
    "    parms = dict()\n",
    "    parms['address'] = address\n",
    "\n",
    "    # encode url to include the address at the end\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "    # retrieve response\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    \n",
    "    # decode response\n",
    "    data = uh.read().decode()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "    # print(data)\n",
    "\n",
    "    # run json.loads\n",
    "    try:\n",
    "        js = json.loads(data)\n",
    "    except:\n",
    "        js = None\n",
    "\n",
    "    # error capture if nothing is received\n",
    "    if not js or 'status' not in js or js['status'] != 'OK':\n",
    "        print('==== Failure To Retrieve ====')\n",
    "        print(data)\n",
    "        continue\n",
    "\n",
    "    # print json\n",
    "    # print(json.dumps(js, indent=4))\n",
    "\n",
    "    pid = js['results'][0]['place_id']\n",
    "    print('Place id', pid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "133602682ceac8dbac470470852ca2735ced8cf8e0bdd97a4df2a7e33d23d50b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
